---
title: "Mixed effects models"
subtitle: '"Wheels within wheels"'
author: "Samuel Robinson, Ph.D."
date: "Oct 6, 2023"
output: 
  beamer_presentation:
    incremental: false
    theme: "default"
    colortheme: "lily"
    highlight: "tango"
    fig_caption: false
urlcolor: blue
df_print: kable
classoption: aspectratio=169   
header-includes: 
  - \definecolor{darkturquoise}{rgb}{0.0, 0.81, 0.82}
  - \useinnertheme{circles}
  - \let\oldShaded\Shaded %Change fontsize of R code chunks
  - \let\endoldShaded\endShaded
  - \renewenvironment{Shaded}{\scriptsize\oldShaded}{\endoldShaded}
  - \let\oldverbatim\verbatim %Change fontsize of code chunk output
  - \let\endoldverbatim\endverbatim
  - \renewenvironment{verbatim}{\tiny\oldverbatim}{\endoldverbatim}
---

```{r setup, include=FALSE}
#Trick to get smaller R code size with out resorting to LaTeX text sizes
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, message=TRUE, 
                      warning=TRUE, cache=TRUE)
library(tidyverse)
theme_set(theme_classic())
library(lme4)
library(ggeffects)
library(ggpubr)
library(glmmTMB)
library(DHARMa)

set.seed(123)

# #Generate data - from earlier lecture
# n <- 150
# ngroups <- 15
# x <- runif(n,-10,10) #Single fixed effect predictor
# g <- sample(letters[1:ngroups],n,TRUE) #Groups
# intercept <- 1
# slopeX <- 0.5
# sigmaR <- 3 #Residual sigma 
# sigmaG <- 5 #Group intercept sigma
# sigmaG_slope <- abs(slopeX*2) #Slope sigma (half slope value)
# 
# #Correlated intercepts and slopes, using Choleski matrices
# raneffs <- matrix(rnorm(ngroups*2,0,1),ncol=2) #Uncorrelated unit normals
# slopeCor <- 0.7 #Intercept-slope correlation
# corMat <- matrix(c(1,slopeCor,slopeCor,1),ncol=2) #Correlation matrix
# cholCorMat <- chol(corMat) #Choleski transform of corMat
# raneffs <- raneffs %*% cholCorMat #Induces correlation in slopes
# raneffs <- raneffs * matrix(rep(c(sigmaG,sigmaG_slope),each=ngroups),ncol=2,
#                             dimnames=list(letters[1:ngroups],c('Int','Slope'))) #Changes SD for each column
# raneff_int <- model.matrix(~g-1) %*% raneffs[,1] #Intercept vector
# raneff_slope <- x * model.matrix(~g-1) %*% raneffs[,2]  #Slope vector
# 
# yhat <- intercept + slopeX*x + raneff_int + raneff_slope  #Expected value
# y <- rnorm(n,yhat,sigmaR) #Data
# dat <- data.frame(y,x,site=g) #Assemble into data frame


#Generate data
n <- 160
ngroups <- 16
x <- runif(n,-10,10) #Single fixed effect predictor
g <- sample(letters[1:ngroups],n,TRUE) #Groups
intercept <- 1
slopeX <- 0.5
sigmaR <- 3 #Residual sigma
sigmaG <- 5 #Group intercept sigma
sigmaG_slope <- abs(slopeX*2) #Slope sigma (half slope value)

#Correlated intercepts and slopes, using Choleski matrices
raneffs <- matrix(rnorm(ngroups*2,0,1),ncol=2) #Uncorrelated unit normals
slopeCor <- 0.7 #Intercept-slope correlation
corMat <- matrix(c(1,slopeCor,slopeCor,1),ncol=2) #Correlation matrix
cholCorMat <- chol(corMat) #Choleski transform of corMat
raneffs <- raneffs %*% cholCorMat #Induces correlation in slopes
raneffs <- raneffs * matrix(rep(c(sigmaG,sigmaG_slope),each=ngroups),ncol=2,
                            dimnames=list(letters[1:ngroups],c('Int','Slope'))) #Changes SD for each column
raneff_int <- model.matrix(~g-1) %*% raneffs[,1] #Intercept vector
raneff_slope <- x * model.matrix(~g-1) %*% raneffs[,2]  #Slope vector

yhat <- intercept + slopeX*x + raneff_int + raneff_slope  #Expected value
y <- rnorm(n,yhat,sigmaR) #Data (normal)
dat <- data.frame(y,x,site=g) #Assemble into data frame
y2 <- rnbinom(n,mu=exp(yhat/5),sigmaR) #Data (NB)
dat2 <- data.frame(y=y2,x,site=g) #2nd data frame with NB data

```

## Outline

::: columns

:::: column

- Linear mixed effects models (LMMs)
  - A bit of math
  - Fixed vs. random effects
  - Random intercepts and slopes
- Generalized linear mixed effects models (GLMMs)
  - Residuals checks
  - Some sage advice
- Hypothesis testing and inference
  - Slopes and intercepts
  - Entire terms
  - AIC and $R^2$

::::

:::: column

![](epicycles.jpg)

::::

:::

# Part 1: Mixed effects models

## Problem: group-level variation

- Sometimes we have to sample within groups: different field sites, individual organisms, etcetera
- However, often we're not really interested in each group _per se_, but in the __average group__
- e.g. "What is the effect of __x__ if you remove group-to-group variation?"
- If you have a small number of groups, you can just include it in your model: 
  - `lm(y ~ x + group)`
  - However, if you have few samples for each group, this can create problems
- Another solution is to use __mixed effects models__

## What are mixed effects models?

Many different names:

1. Mixed effects models
2. Random effects models
3. Hierarchical models
4. Empirical/Bayesian hierarchical models
5. Latent variable models
6. Split-plot models
7. Variance partitioning

I usually use the term _heirarchical models_, as this is the closest to what I will teach you

## Scary math

Unfortunately, we need a review of matrix algebra in order to explain this:

- This is a matrix: $$ A = \begin{bmatrix}
1 & 4 & 7 \\
2 & 5 & 8 \\
3 & 6 & 9
\end{bmatrix}
$$
  
- This is a vector: $$ b = \begin{bmatrix}
1 & 2 & 3 
\end{bmatrix}
$$
  
- Multiplying them looks like this:

$$ A \times b = Ab = 1 \times \begin{bmatrix}
1  \\
2 \\
3 
\end{bmatrix} + 2 \times \begin{bmatrix}
4  \\
5  \\
6 
\end{bmatrix} + 3 \times \begin{bmatrix}
7  \\
8 \\
9 
\end{bmatrix} = \begin{bmatrix}
30  \\
36 \\
42 
\end{bmatrix}$$

## Why do we call them "linear models"?

- _Linear_ mapping of __coefficients__ onto a __model matrix__ (from your data)

- Coefficients: $$ \beta = \begin{bmatrix}
0.1 & 1.8 & -0.03 
\end{bmatrix}
$$

- Model matrix: $$ X = \begin{bmatrix}
1 & 1 & 10 \\
1 & 1 & 12 \\
1 & 0 & 9 \\
\vdots & \vdots & \vdots
\end{bmatrix}
$$

- Multiplying them looks like: $$ \hat{y} = X\beta = 
\begin{bmatrix}
1.60  \\
1.54 \\
-0.17 \\
\vdots
\end{bmatrix}$$

## This is exactly what R does to fit models:

```{r, echo=TRUE, size='tiny'}
head(dat)
m1 <- lm(y~x,data=dat) #Uses x to predict y
summary(m1)
```

## This is exactly what R does to fit models (cont.):

```{r, echo=TRUE, size='tiny'}
head(model.matrix(m1))
coef(m1)
pred2 <- model.matrix(m1) %*% coef(m1) #predicted = matrix * coefs
head(data.frame(pred1=predict(m1),pred2)) #same thing!
```

## Groups are coded by "dummy variables" (0s and 1s)

```{r, echo=TRUE, size='tiny'}
m2 <- lm(y~site,data=dat) #Use site to predict y
head(model.matrix(m2)) #0s and 1s used to identify groups
coef(m2) #This uses the 1st site as the "control" group
```

## Structure of LMs... now with matrices!

- All linear models take the form:
\begin{equation*} 
\begin{split}
\textcolor{orange}{\hat{y}} & = \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} = \textcolor{blue}{b_0}\textcolor{darkturquoise}{1} + \textcolor{blue}{b_1}\textcolor{darkturquoise}{x_1} ... + \textcolor{blue}{b_i}\textcolor{darkturquoise}{x_i} \\
y & \sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma})
\end{split}
\end{equation*}

- $y$ is a vector of data you want to predict
- $\textcolor{orange}{\hat{y}}$ is a vector of _predicted values_ for $y$
- $\textcolor{darkturquoise}{X} = \textcolor{darkturquoise}{\{1,x_1...\}}$ is a matrix of _predictors_ for _y_
- $\textcolor{blue}{\beta} = \textcolor{blue}{\{b_0,b_1,...\}}$ is a vector of _coefficients_
- $y\sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma})$ means:
  - "$y$ follows a Normal distribution with mean $\textcolor{orange}{\hat{y}}$ and SD $\textcolor{red}{\sigma}$"
  
## Fixed effects vs. Random effects

Say that $\textcolor{darkturquoise}{X}$ is a model matrix coding for a bunch of sites\footnotemark, and _y_ is something we're interested in predicting

::: columns

:::: column

\begin{equation*}
\begin{split}
\textcolor{orange}{\hat{y}} & = \textcolor{blue}{b_0} + \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} \\
y & \sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma})
\end{split}
\end{equation*}

\hfill\newline

- Site coefficients ($\textcolor{blue}{\beta}$) are unrelated to each other
- $\textcolor{red}{\sigma}$ is the SD of _residuals_
- Site is a __fixed effect__

::::

:::: column

\begin{equation*}
\begin{split}
\textcolor{orange}{\hat{y}} & = \textcolor{blue}{b_0} + \textcolor{darkturquoise}{X}\textcolor{purple}{\zeta} \\
y & \sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma}) \\
\textcolor{purple}{\zeta} & \sim Normal(0,\textcolor{red}{\sigma_{site}})
\end{split}
\end{equation*}

- Site coefficients ($\textcolor{purple}{\zeta}$) are related to each other via a _Normal_ distribution
- $\textcolor{red}{\sigma}$ is the SD of _residuals_, $\textcolor{red}{\sigma_{site}}$ is the SD of _sites_
- Site is a __random effect__

::::

:::


\footnotetext{Intercept is a separate variable}

## Mixed effects = fixed + random effects

A mixed effects model has both __fixed__ and __random__ effects

\begin{equation*}
\begin{split}
\textcolor{orange}{\hat{y}} & = \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} + \textcolor{gray}{U}\textcolor{purple}{\zeta} \\
y & \sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma}) \\
\textcolor{purple}{\zeta} & \sim Normal(0,\textcolor{red}{\sigma_{site}})
\end{split}
\end{equation*}

- $\textcolor{darkturquoise}{X}$ = fixed effects matrix (e.g. intercept, temperature)
- $\textcolor{blue}{\beta}$ = fixed effects coefficients
- $\textcolor{gray}{U}$ = random effects matrix (e.g. sites)
- $\textcolor{purple}{\zeta}$ = random effects coefficients
- $\textcolor{red}{\sigma}$, $\textcolor{red}{\sigma_{site}}$ = variance terms

## Mixed effect model example

Let's go back to our earlier example:

- We're interested in predicting _y_ using _x_ (fixed effects)
- Data was collected at a number of _sites_, which may affect _y_ "somehow"
- Effect of each site is normally distributed

```{r lmerExample, echo=TRUE, message=FALSE, warning=FALSE, size='tiny'}
head(dat)
```

## Mixed effect model example

::: columns

:::: column

```{r, echo=TRUE, size='tiny'}
library(lme4) #Mixed effects library 
#site is fit as a random intercept
mm1 <- lmer(y ~ x + (1|site),data=dat) 
summary(mm1)
```

::::

:::: column

Results from `lmer` model:

- Random effects:
  - _residual_ and _site_ variance ($\textcolor{red}{\sigma}$, $\textcolor{red}{\sigma_{site}}$)
- Fixed effects: 
  - Intercept and slope estimates ($\textcolor{blue}{\beta}$)
  - No d.f. and p-value \footnotemark
  - If you need p-values for parameters, you can use the [_lmerTest_](https://rdocumentation.org/packages/lmerTest/versions/3.1-3/topics/lmerTest-package) package (or just calculate them yourself using means/SEs)

::::

:::

\footnotetext{`lme4` author doesn't think they can be calculated. I somewhat agree}

## Mixed effect model results

::: columns

:::: column

- In a _random intercepts_ model, the regression line of _x_ on _y_ is allowed to move up or down around the main regression line for each site

- These changes in intercepts are _normally distributed_

::::

:::: column

```{r lmerPlot, fig.height=4, fig.width=4, warning=FALSE, message=FALSE}
p1 <- dat %>% mutate(pred=predict(mm1),gpred=predict(mm1,re.form=~0)) %>% 
  ggplot(aes(x=x,y=y,col=site))+
  geom_point(show.legend = FALSE)+
  geom_line(aes(y=gpred),col='black',linewidth=2)
p1 + geom_line(aes(y=pred),show.legend = FALSE)+guides(col=guide_legend(ncol=2))
```

::::

:::

## Mixed effect model results (cont.)

- For plotting, we want a partial effects plot that marginalizes across sites (i.e. "What does the trend look like at the average site?")
- `ggpredict` works well for this. If you want partial residuals, you'll have to add them in yourself using `predict` and `residual`

```{r, fig.height=2, fig.width=5.5,warning=FALSE}
p2 <- ggpredict(mm1,terms='x') %>% data.frame() %>% #Gets predictions from mm1
  ggplot(aes(x=x))+ #Plots using ggplot
  geom_ribbon(aes(ymax=conf.high,ymin=conf.low),alpha=0.3) + #Intervals
  geom_line(aes(y=predicted))
ggarrange(p1+geom_line(aes(y=pred),show.legend = FALSE)+ylim(-15,20),
          p2+ylim(-15,20)+labs(y='y'),
          ncol=2,legend = 'none')
```

## First challenge

How does forest cover influence fish size? Maybe some of the species do better in forested streams?

::: columns

:::: column

- You've weighed fish in streams with different forest covers (`fishMass.csv`). However, perhaps some of the variation is caused by "other things" about the site?
- Fit a mixed effects model with the fixed effects you're interested in (__forest cover__, __species__), and include __site__ as a random _intercept_
- How does this compare to a simple linear model where you _ignore_ site?

:::: 

:::: column

```{r message=FALSE, warning=FALSE,fig.width=5,fig.height=5}
fishDat <- read.csv('./fishMass.csv')

ggplot(fishDat,aes(x=forest,y=mass,col=species))+
  geom_point()+
  geom_smooth(method='lm')+
  scale_colour_brewer(type = 'qual')+
  labs(x='Forest cover (%)',y='Mass')
```

::::

:::

## First challenge results

::: columns

:::: column

```{r}
m1 <- lm(mass~species*forest,data=fishDat) #Ignores site
summary(m1)
```

::::

:::: column

```{r}
m2 <- lmer(mass~species*forest+(1|sites),data=fishDat) #Site as a random intercept
summary(m2)
```

::::

:::

## First challenge results (cont.)

::: columns

:::: column

`lm(mass~forest*species)`

```{r echo=FALSE, warning=FALSE,warning=FALSE,message=FALSE,fig.width=4,fig.height=4}
ggpredict(m1,terms=c('forest','species')) %>% data.frame() %>% 
  mutate(group=factor(group,levels=c('Spp1','Spp2','Spp3'))) %>% 
  ggplot(aes(x=x))+
  geom_ribbon(aes(ymax=conf.high,ymin=conf.low,fill=group),alpha=0.3)+
  geom_line(aes(y=predicted,col=group))+
  scale_colour_brewer(type = 'qual',aesthetics = c('colour','fill'))+
  labs(x='Forest cover (%)', y='Mass',col='Species',fill='Species',
       title='Fixed effects model')
  
```

::::

:::: column

`lmer(mass~forest*species+(1|sites))`

```{r echo=FALSE,warning=FALSE,message=FALSE,fig.width=4,fig.height=4}
ggpredict(m2,terms=c('forest','species')) %>% data.frame() %>%
  mutate(group=factor(group,levels=c('Spp1','Spp2','Spp3'))) %>% 
  ggplot(aes(x=x))+
  geom_ribbon(aes(ymax=conf.high,ymin=conf.low,fill=group),alpha=0.3)+
  geom_line(aes(y=predicted,col=group))+
  scale_colour_brewer(type = 'qual',aesthetics = c('colour','fill'))+
  labs(x='Forest cover (%)', y='Mass',col='Species',fill='Species',
       title='Mixed effects model')
```

::::

:::


## More random effects: slopes!

::: columns

:::: column

```{r echo=FALSE, fig.width=4, fig.height=4}
dat %>% 
  mutate(pred=predict(mm1),gpred=predict(mm1,re.form=~0)) %>% 
  ggplot(aes(x=x,y=y,col=site))+
  geom_point()+
  geom_line(aes(y=pred))+
  geom_line(aes(y=gpred),col='black',linewidth=2)+
  theme(legend.position = 'none')
```

::::

:::: column

```{r echo=FALSE,fig.width=5, fig.height=5}
mm2 <- lmer(y ~ x + (x|site),data=dat) 

dat %>% mutate(pred=predict(mm2),gpred=predict(mm2,re.form=~0)) %>% 
    ggplot(aes(x=x,y=y,col=site))+
  geom_point()+
  geom_line(aes(y=pred))+
  geom_line(aes(y=gpred),col='black',linewidth=2)+
  theme(legend.position = 'none')

```

::::

:::


## Random slopes + intercepts

Suppose that _y_ wasn't just higher or lower at each site, but that the effect of _x_ on _y_ was higher or lower at each site

\begin{equation*}
\begin{split}
\textcolor{orange}{\hat{y}} & = \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} + \textcolor{gray}{U}\textcolor{purple}{\zeta_{int}} + \textcolor{gray}{U\textcolor{darkturquoise}{_x}}\textcolor{purple}{\zeta_{slope}} \\
y & \sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma}) \\
\textcolor{purple}{\zeta_{int}} & \sim Normal(0,\textcolor{red}{\sigma_{int}}) \\
\textcolor{purple}{\zeta_{slope}} & \sim Normal(0,\textcolor{red}{\sigma_{slope}})
\end{split}
\end{equation*}

- $\textcolor{darkturquoise}{X}$ = fixed effects matrix (e.g. intercept, temperature)
- $\textcolor{blue}{\beta}$ = fixed effects coefficients
- $\textcolor{gray}{U}$ = random intercept matrix (e.g. sites)
- $\textcolor{gray}{U\textcolor{darkturquoise}{_x}}$ = random slopes matrix (e.g. temperature)
- $\textcolor{purple}{\zeta_{int}}, \textcolor{purple}{\zeta_{slope}}$ = random intercept and slope coefficients
- $\textcolor{red}{\sigma},\textcolor{red}{\sigma_{int}},\textcolor{red}{\sigma_{slope}}$ = variance terms

## Random slope and intercept example:

::: columns

:::: column

```{r lmerExample2, echo=TRUE, size='tiny'}
#Intercept varies with site, and slope of x can
#   also vary with site (both hierarchical)
mm2 <- lmer(y ~ x + (x|site),data=dat) 
summary(mm2)
```

::::

:::: column

\hfill\newline

Results from `lmer` model:

- Random effects:
  - _residual_, _slope_, and _site_ variance ($\textcolor{red}{\sigma}$, $\textcolor{red}{\sigma_{int}}$, $\textcolor{red}{\sigma_{slope}}$)
  - Correlation b/w intercept and slope = `r round(attr(VarCorr(mm2)[[1]],which='correlation')[1,2],2)`
    - Sites with higher intercept _also_ have a higher slope
- Fixed effects: 
  - Intercept and slope estimates
  
::::

:::

## Model matrices

$\textcolor{darkturquoise}{X}$: Fixed effects model matrix

```{r}
head(model.matrix(mm2))
```


::: columns

:::: column

$\textcolor{gray}{U}$: Random intercept model matrix 

```{r}
options(width = 60)
head(model.matrix(~site-1,data=dat))
```

::::

:::: column

$\textcolor{gray}{U\textcolor{darkturquoise}{_x}}$: Random slope model matrix

```{r}
options(width = 60)
head(round(model.matrix(~site-1,data=dat) * dat$x,2))
```
::::

:::

## Mixed effect model results

- Regression line of _x_ on _y_ is allowed to move up or down for each site (random intercepts)
- Slope of regression line can be more or less steep for each site (random slopes)
- Changes in intercepts and slopes are _normally distributed_, and in this example are _correlated_ with each other 

```{r lmerPlot2, fig.height=2.5, fig.width=6}
dat %>% mutate(pred=predict(mm2),gpred=predict(mm2,re.form=~0)) %>% 
  ggplot(aes(x=x,y=y,col=site))+
  geom_point()+
  geom_line(aes(y=gpred),col='black',linewidth=2) +
  geom_line(aes(y=pred))+theme(legend.position = 'none')
```

<!-- ## Mixed effect model validation -->

<!-- - Similar to linear models, but we _also_ check whether the random intercepts are normally distributed -->
<!-- <!-- - If one site intercept is very different from the others, this is a clue for investigation! --> -->

<!-- ```{r} -->
<!-- par(mfrow=c(2,3)) -->
<!-- plot(fitted(mm2),resid(mm2,type='working'),xlab='Fitted values',ylab='Working residuals'); abline(h=0) -->
<!-- qqnorm(resid(mm2,type='working'),main='Residuals');qqline(resid(mm2,type='working')) -->
<!-- qqnorm(ranef(mm2)$site[,1],main='Random Intercepts');qqline(ranef(mm2)$site[,1]) -->
<!-- qqnorm(ranef(mm2)$site[,2],main='Random Slopes');qqline(ranef(mm2)$site[,2]) -->
<!-- plot(ranef(mm2)$site,xlab='Random Intercept',ylab='Random Slope',main='Intercept-Slope Correlation') -->
<!-- # par(mfrow=c(1,1)) -->
<!-- ``` -->

<!-- ## Hypothesis testing -->

<!-- Is this fixed effect important? (e.g. ANOVA) -->

<!-- - Use likelihood-based test via `drop1` (likelihood ratio test, AIC) -->
<!-- - Be careful to fit model with `REML = FALSE`! -->

<!-- ```{r, echo=TRUE, text='tiny'} -->
<!-- mm1 <- update(mm1,REML=FALSE) #Refit model using ML rather than REML -->
<!-- drop1(mm1,test='Chisq') #x has a very strong effect! -->
<!-- ``` -->

## Why do we need to do any of this?

_"My supervisor told me to just use site as a fixed effect. Why can't I do that?"_ 

- You can do it this way, but you may encounter the following problems:
  - You lose the _partial pooling_ that occurs in mixed effects models = Worse estimates of site effects!
  - You lose 1 d.f. for each site = Type II error $\uparrow$ = You may not find the fixed effect of interest, even if it's there!
  - Sites with low sample sizes may cause your models to break
  - People who have read statistics books published after 1980 may ask questions
- However, if you have a low number of sites (1-10), fixed effects may work better
  - Hard to estimate $\sigma_{site}$ if number of sites is low
  - If stakes are high, it may be better to be more conservative about site intercepts
  - Easier to interpret (p-values, ANOVA, etc.)
  
## Example of partial pooling effect (shrinkage)

```{r partPool, fig.fullwidth=7,fig.height=4}
m1b <- lm(y~x+site-1,data=dat)

a1 <- data.frame(ggpredict(m1b,terms='site')) %>% 
  mutate(x=as.character(x)) %>% arrange(x) %>% 
  select(x,predicted)
a2 <- data.frame(ggpredict(mm1,terms='site',type='random')) %>% 
  select(-group)
bind_rows(a1,a2,.id='mod') %>% mutate(mod=factor(mod,labels=c('fixed','random'))) %>% 
  ggplot(aes(x=x,y=predicted,col=mod))+geom_point()+
  geom_hline(yintercept = 0,linetype='dashed')+
  scale_colour_manual(values=c('blue','red'))+
  labs(x='Site',y='Predicted',col='Model')
```

\pause

Random intercept "pulls in" sites with extreme values towards zero   

## Second challenge

- Let's go back to the fish weight model...
- Fit a mixed effects model with the fixed effects you're interested in (__forest cover__, __species__), and include __site__ as a random effect (_intercept_ __or__ _slope_)
- Your supervisor doesn't like hierarchical models, and tells you to just use site as another fixed term in an `lm` model. Do you get different results if you use their approach?

## Second challenge results

```{r secondChallenge, warning=FALSE, fig.fullwidth=TRUE,fig.height=5}

#Fit model
m0 <- lm(mass~species*forest-1,data=fishDat) #Ignores sites (pseudoreplication)
m1 <- lmer(mass~species*forest-1+(1|sites),data=fishDat) #Site as a random intercept
m2 <- lmer(mass~species*forest-1+(forest|sites),data=fishDat) #Site as a random intercept + slope
m3 <- lm(mass~species*forest+sites-1,data=fishDat) #"My supervisor told me to"
m4 <- lm(mass~species*forest+forest*sites-1,data=fishDat) #"My supervisor told me to 2"

getCoefs <- function(mod,mult=1.96){ #Extract fixed effects coefficients + SEs
  if(class(mod)=='lmerMod'){
    est <- fixef(mod)
  } else {
    est <- coef(mod)
  }
  se <- sqrt(diag(vcov(mod)))
  upr <- est+se*mult
  lwr <- est-se*mult
  d <- data.frame(est,se,upr,lwr)
  return(d)
}

modList <- list(m0=m0,m1=m1,m2=m2,m3=m3,m4=m4)

modLabels <- sapply(modList,function(x){ #Get labels from model formula
  f <- as.character(formula(x))
  f <- paste(f[2],f[1],f[3],collapse='')
  f <- gsub(' - 1','',f)
  f <- gsub('\\s','',f)
})

fixCoef <- c(35,20,50,0.01,0.05,-0.15) #Actual coefficients

#Plot of coefficients
lapply(modList,getCoefs) %>% do.call('rbind',.) %>% 
  rownames_to_column('coef') %>% 
  separate(coef,c('mod','coef'),sep='\\.') %>% 
  filter(!grepl('sites',coef)) %>% 
  bind_rows(.,data.frame(mod='actual',coef=names(coef(m0)),est=fixCoef,se=0,upr=NA,lwr=NA)) %>% 
  mutate(mod=factor(mod,levels=rev(unique(mod)),labels=c('actual',rev(modLabels))),
         coef=factor(coef,levels=names(coef(m0)))) %>% 
  ggplot(aes(x=mod,y=est))+
  geom_pointrange(aes(ymax=upr,ymin=lwr,col=ifelse(mod=='actual','a','b')),
                  position=position_dodge(width=0.5),show.legend = FALSE)+
  geom_hline(yintercept=0,linetype='dashed')+
  facet_wrap(~coef,scales='free')+
  labs(y='Estimate',x='Model')+
  scale_colour_manual(values=c('black','red'))+
  coord_flip()

```


## Second challenge results (cont.):

```{r secondChallenge2, fig.fullwidth=TRUE,fig.height=5.5}
#Get dataframe of predictions from models
getPreds <- function(mod,t=c('forest','species')){ 
  ggpredict(mod,terms=t) %>% data.frame(.)
}

#Model predictions
modPreds <- do.call('rbind',lapply(modList,getPreds)) %>% 
  rownames_to_column('mod') %>% 
  separate(mod,c('mod','temp'),sep='\\.') %>% select(-temp) %>% 
  mutate(mod=factor(mod,labels=modLabels))

#Colours
colValues <- c('red','purple','blue')

actualMeans <- with(fishDat,data.frame(forest,species,pred=model.matrix(m0) %*% fixCoef))

ggplot(modPreds,aes(x=x,y=predicted))+geom_ribbon(aes(ymax=conf.high,ymin=conf.low,fill=group),alpha=0.3)+
  geom_line(aes(col=group),linewidth=1)+
  geom_line(data=actualMeans,aes(x=forest,y=pred,group=species),col='black',linewidth=1)+
  facet_wrap(~mod)+
  labs(y='mass',x='forest',col='Species',fill='Species')+
  scale_fill_manual(values=colValues)+
  scale_colour_manual(values=colValues)
```


# Part 2: GLMMs

## What if my response variable is non-normal?

::: columns

:::: column

- Linear model (LM)

\begin{equation*}
\begin{split}
\textcolor{orange}{\hat{y}} & = \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} \\
y & \sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma})
\end{split}
\end{equation*}

::::

:::: column

- Generalized linear model (GLM)

\begin{equation*}
\begin{split}
logit(\textcolor{orange}{\hat{\phi}}) & = \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} \\
y & \sim Binomial(\textcolor{orange}{\hat{\phi}})
\end{split}
\end{equation*}

::::

:::

::: columns

:::: column

\vspace{12pt}

- Linear mixed effects model (LMM)

\begin{equation*}
\begin{split}
\textcolor{orange}{\hat{y}} & = \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} + \textcolor{gray}{U}\textcolor{purple}{\zeta} \\
y & \sim Normal(\textcolor{orange}{\hat{y}},\textcolor{red}{\sigma}) \\
\textcolor{purple}{\zeta} & \sim Normal(0,\textcolor{red}{\sigma_{site}})
\end{split}
\end{equation*}

::::

:::: column

\vspace{12pt}

- Generalized linear mixed effects model (GLMM)

\begin{equation*}
\begin{split}
logit(\textcolor{orange}{\hat{\phi}}) & = \textcolor{darkturquoise}{X}\textcolor{blue}{\beta} + \textcolor{gray}{U}\textcolor{purple}{\zeta} \\
y & \sim Binomial(\textcolor{orange}{\hat{\phi}}) \\
\textcolor{purple}{\zeta} & \sim Normal(0,\textcolor{red}{\sigma_{site}})
\end{split}
\end{equation*}

::::

:::


## How do I fit GLMMs?

- `glmer()` and `glmer.nb()` from `lme4` work for Binomial, Poisson, and Negative Binomial data

```{r glmerNBexample, echo=TRUE, eval=FALSE}
library(lme4)
glmm1 <- glmer.nb(y~x+(x|site),data=dat2) #Negative binomial GLMM
summary(glmm1) #glmer.nb takes a long time to run
```

- `glmmTMB()` from `glmmTMB` works for those above, _plus_ a bunch of others (Zero-inflation, Beta-binomial), and it's generally faster

```{r glmmTMBexample, echo=TRUE, eval=FALSE}
library(glmmTMB)
glmm2 <- glmmTMB(y~x+(x|site),data=dat2,family=nbinom2())
summary(glmm2) #Similar results, but quicker
```

## Fitting GLMMs

::: columns

:::: column

```{r glmerNBexample, echo=FALSE, eval=TRUE, size='tiny'}
```

::::

:::: column

```{r glmmTMBexample, echo=FALSE, eval=TRUE, size='tiny'}
```

::::

:::

## Residual checks for LMMs/GLMMs

- Unfortunately, residual plotting functions aren't set up for mixed effects models. However, you can extract deviance residuals from `lmer`, `glmer`, or `glmmTMB` models and make your own plots:

- Added complication: __we also need to check whether the random effects are normally distributed__

```{r lmmResid, echo=TRUE, eval=FALSE}
#Example with LMMs (fish model from before)
devRes <- residuals(m2,type='deviance') #Get deviance residuals
m2RE <- ranef(m2)$sites #Get random effects (intercept + slope)
par(mfrow=c(2,2))
plot(fitted(m2),devRes,xlab='Fitted',ylab='Deviance residual',main='Residuals'); abline(h=0,lty=2)
qqnorm(devRes,main='Residual Q-Q'); qqline(devRes) #Deviance residual Q-Q
qqnorm(m2RE[,1],main='Intercepts Q-Q'); qqline(m2RE[,1]) #Intercepts
qqnorm(m2RE[,2],main='Slopes Q-Q'); qqline(m2RE[,2]) #Slopes Q-Q
par(mfrow=c(1,1))
```

## Residual checks for LMMs/GLMMs (cont.)

```{r lmmResid, echo=FALSE, eval=TRUE, fig.fullwidth=TRUE,fig.height=6}
```

## Alternative approach: simulation

- Residual plots can be misleading, and can hide information from you. A better way is to compare a set of _simulated data_ from your model to the _actual data_
- The `simulateResiduals` from `DHARMa` (see [here](https://cran.r-project.org/web/packages/glmmTMB/vignettes/model_evaluation.pdf)) works well for `glmmTMB` models, as well as LMs, GLMs, and more, so it's worth learning

```{r dharmaPlot, message=FALSE, warning=FALSE, fig.height=4, fig.fullwidth=TRUE}
library(DHARMa)
glmm2_res <- simulateResiduals(glmm2)
plot(glmm2_res) #No residual problems here
```

## Simulation (cont.)

- `DHARMa` also has useful functions for checking overdispersion and zero-inflation. Both of these tests indicate that a) this model is not overdispersed, and b) there seems to be no zero-inflation (see [here](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html) for more examples)

::: columns

:::: column

```{r dispTest, warning=FALSE, message=FALSE, fig.width=5,fig.height=4}
testDispersion(glmm2_res)
```
::::

:::: column

```{r ziTest, warning=FALSE, message=FALSE,fig.width=5,fig.height=4}
testZeroInflation(glmm2_res)
```

::::

:::

## Partial residual plots for `glmmTMB` models

- `ggpredict()` from `library(ggeffects)` works with `glmmTMB` models

```{r glmmPredict, fig.width=7,fig.height=3.5}
library(ggeffects)
glmm2_eff <- ggpredict(glmm2,terms='x')
plot(glmm2_eff)
```

## Third challenge

- Remember that `canolaPlants.csv` data I gave you last week, which you all dutifully fit GLMs of? (See [here](https://github.com/samuelVJrobinson/ecoStatsLectures/tree/fall2023/04%20GLMs))
- That `Field` column indicates which farmer's field the plants came from. You'll also notice that there are groupings at each `Distance`, indicating distinct `Plots` that each plant came from.
- Fit a GLMM of pod success with distance, using Field and Plot as random effects.
- Check the assumptions of your model with `DHARMa`.

## Third challenge results

::: columns

:::: column

```{r canolaMod}
options(width = 60)
canolaDat <- read.csv('../04 GLMs/canolaPlants.csv') %>%
  filter(Missing>=0,Pods>0) %>% mutate(Field=factor(Field)) %>%
  mutate(Plot=factor(paste(Year,Field,Distance,sep='_')))
canMod <- glmmTMB(cbind(Pods,Missing)~Year+VegMass+Distance+(VegMass|Field/Plot),data=canolaDat,family = 'binomial')
summary(canMod)
```

::::

:::: column

```{r canolaModPlot,width=4,height=6,warning=FALSE,message=FALSE}
plot(ggpredict(canMod,terms=c('VegMass')))+
  labs(x='Plant size',y='Pod success',
       title='Big plants have proportionally more pods')
```

::::

:::

## Third challenge results (cont.)

```{r canModRes, warning=FALSE, message=FALSE,fig.fullwidth=TRUE,fig.height=5}
canModRes <- simulateResiduals(canMod,n=1000)
plot(canModRes)
```

## Third challenge results (cont.)

```{r canModOutliers,fig.fullwidth=TRUE,fig.height=5}
testOutliers(canModRes,type='bootstrap',nBoot=100)
```

## Third challenge results (cont.)

```{r canModDisp,fig.fullwidth=TRUE,fig.height=5}
testDispersion(canModRes)
```

# Part 3: Hypothesis testing and inference

## I fit a model... now what?

- Congratulations, your model ran and it met the assumptions of regression...
- Time to see if your predictions are supported by your data!
- For each of the terms in your model:
  - Was the term "important" for your model?
  - If so, what direction was the effect in?
- How well did your model fit your data (overall)?
- Some other sage advice

## Step 1: was the term "important"?

In linear models, this is done using an ANOVA F-test (also shown at the bottom of a `summary()` statement):

```{r anovaLM}
lmMod1 <- lm(mpg~disp+gear,data=mtcars)
anova(lmMod1)
```

## But wait, there's more!

Unfortunately, if we have more than 1 term in the model, the order of terms can change your answer:

```{r}
#lmMod1 <- lm(mpg~disp+gear,data=mtcars)
lmMod2 <- lm(mpg~gear+disp,data=mtcars)
```

-
  ```{r }
  anova(lmMod1)
  ```

-
  ```{r}
  anova(lmMod2)
  ```

## Solution: use a Type II ANOVA

- We're usually interested in the importance of a term on its own, _not just after other terms are accounted for_ (Type I ANOVA).

- For this, we use a Type II ANOVA. This can be done using `drop1()` (or `Anova()` in the `car` package)

-
  ```{r}
  drop1(lmMod1,test='F')
  ```

-
  ```{r}
  drop1(lmMod2,test='F') #Same as above
  ```

## Interactions make ANOVA testing a bit strange

- If interactions are present, it doesn't really make sense to test the main terms __because they depend on the interactions__
- For example:
  ```{r}
  lmMod3 <- lm(mpg ~ gear*disp,data=mtcars)
  drop1(lmMod3,test='F')
  ```
- `Anova` from the `car` package tests other terms _after_ interactions, but the meaning isn't the same. I prefer to keep things simple and just use `drop1()`
  ```{r}
  car::Anova(lmMod3,type='II')
  ```

## GLMs, LMMs, and GLMMs

::: columns

:::: column

- `drop1` also works with GLMs, LMMs, and GLMMs, but we use a $\chi^2$ _likelihood ratio test_ rather than an F-test

- Unfortunately, different numbers of data points change your likelihood, so this can wreck LRTs. This happens a lot if you have NAs in your predictor columns, so _clean up your data before using it in models_.

::::

:::: column

```{r, echo=TRUE}
drop1(m1,test='Chisq')
```

::::

:::

## ML vs REML - a mathematical aside

- Maximum likelihood (ML) estimates of variance (e.g. SD) are always smaller than the actual variance (biased)
- Restricted maximum likelihood (REML) uses a mathematical trick to get around this, but...
- This means that models with _different numbers of fixed effects_ don't have the same REML estimates
- Likelihood between these models technically can't be compared!

Solution:

  1. Use ML if comparing between models with different fixed effects, then...
  2. Re-fit with REML once you've decided on a model

## Step 2: what was the direction of the effect?

How do I know this effect is different from _x_? (Usually zero)
- Use Wald Z-test (2-sided p-value from Z-test)

```{r, echo=TRUE}
mm1 <- update(mm1,REML=TRUE) #Reset to REML
meanEst <- fixef(mm1)[2] #Get mean
seEst <- sqrt(vcov(mm1)[2,2]) #Get standard error
(1-pnorm(meanEst/seEst,0,1))*2 #p-value from 2-sided Z-test
```

- `glht` from `library(multcomp)` works with `lmer` models if you are comparing between coefficients (e.g. "Is treatment A different from B and C?")

## Step 3: How well did your model fit your data?

In a simple linear model, a common measure of model fit is _adjusted_ $R^2$, which can be found in the `summary()` statement

```{r}
summary(m0)
```

## How well did your model fit your data? (cont.)

- For GLMs, LMMs, and GLMMs, there isn't really one standard way to get "$R^2$". See [here](https://doi.org/10.1111/j.2041-210x.2012.00261.x) for a widely-read paper on the topic
- Likelihood Ratio Tests or AIC (_Akaike's Information Criterion_) can be used to compare between different models _of the same dataset_, but likelihood and AIC don't mean anything on their own
- Both `MuMIn` and `r2glmm` implement versions of the Nakagawa $R^2$ for mixed effects models. _Caveat emptor_:

::: columns

:::: column

```{r, warning=FALSE}
library(MuMIn)
r.squaredGLMM(m1)
```
::::

:::: column

```{r, warning=FALSE}
library(r2glmm)
r2beta(m1, method = 'nsj',partial=FALSE)
```
::::

:::

- Size of the random effects (variance components) can give you an idea of how large the between-group variance was compared to residual variance. Useful for planning future field work or experiments!

## Some final advice

- LMMs and GLMMs are _hard_ to both understand and fit. They are not as forgiving as LMs and GLMs, and will often fail to fit, take a very long time, or give you very strange answers without any explanation.
  - Check the model output and make sure the coefficients and SEs aren't weirdly large or small
  - Andrew Gelman's Modeling Rule-of-Thumb: "It's not me, it's you!"
- My advice: Once you have a model you'd like to fit, start off with simpler "incorrect" version of it, and add terms until you have the final "correct" model
- In the canola model, I started off with a Field-level intercept, then added a Plot-level intercept, and finally a random slope term
- One of my interim models had a random `Distance` slope term, which caused the model to fail (reason: only 1 distance per plot!)

\centering __Avoid selecting models based on $R^2$ or AIC alone. Think about how the system works!__

